{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "601ff85b",
   "metadata": {},
   "source": [
    "# ANBW Model Comparsion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d497dc78",
   "metadata": {},
   "source": [
    "## Comparsion Model\n",
    "- Dacon Baseline Model\n",
    "- EfficientNet B0\n",
    "- EfficientNet B1\n",
    "- EfficientNet B2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd3617",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7fadf8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T09:53:12.585020Z",
     "start_time": "2021-08-22T09:53:12.572013Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad534507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T09:53:17.498921Z",
     "start_time": "2021-08-22T09:53:12.589025Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a73791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T09:53:17.619924Z",
     "start_time": "2021-08-22T09:53:17.502928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA avilable: True\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA avilable:\",\n",
    "     True if tf.config.list_physical_devices(\"GPU\") else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e95b34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T09:53:17.649933Z",
     "start_time": "2021-08-22T09:53:17.622921Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, path, fraction, resize = None):\n",
    "        self.path = path\n",
    "        self.fraction = fraction\n",
    "        self.resize = resize\n",
    "        self.SEED = int(np.random.rand() * 10000)\n",
    "        self.show_info()\n",
    "    \n",
    "    def show_info(self):\n",
    "        print(\"========================================\")\n",
    "        print(f\"path: {self.path}\")\n",
    "        print(f\"fraction: {self.fraction}\")\n",
    "        print(f\"resize: {self.resize}\")\n",
    "        print(f\"SEED: {self.SEED}\")\n",
    "        print(\"========================================\")\n",
    "    \n",
    "    def read_csv(self):\n",
    "        if self.path == None or os.path.isfile(self.path) == False:\n",
    "            raise Exception(f\"Invalid path: {self.path}\")\n",
    "        train = pd.read_csv(f\"{self.path}\")\n",
    "        return train\n",
    "    \n",
    "    def reshape(self, raw_data):\n",
    "        features = raw_data.drop([\"id\", \"digit\", \"letter\"], axis=1).values\n",
    "        features = features.reshape(-1, 28, 28, 1)\n",
    "        features = np.where((features<=20)&(features!=0), 0., features)\n",
    "        features = features / 255\n",
    "        features = features.astype(\"float32\")\n",
    "        return features\n",
    "    \n",
    "    def resize(self, images):\n",
    "        resized_images = np.zeros([len(images), self.reshape, self.reshape, 3], dtype=np.float32)\n",
    "        \n",
    "        for id, image in enumerate(images):\n",
    "            converted = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "            resized = cv2.resize(converted, (self.resize, self.resize), interpolation=cv2.INTER_CUBIC)\n",
    "            del converted\n",
    "            resized_images[id] = resized\n",
    "            del resized\n",
    "            gd.collect()\n",
    "        \n",
    "        return resized_images\n",
    "    \n",
    "    def label_to_vector(self, raw_data):\n",
    "        labels = raw_data[\"digit\"]\n",
    "        labels_vector = np.zeros((len(labels), len(labels.unique())))\n",
    "        \n",
    "        for id, digit in enumerate(labels):\n",
    "            labels_vector[id, digit] = 1\n",
    "        \n",
    "        return labels_vector\n",
    "    \n",
    "    def split(self, x_train, y_train):\n",
    "        x_splited_train, x_splited_val, y_splited_train, y_splited_val = train_test_split(x_train, y_train, test_size=self.fraction, random_state=self.SEED, shuffle=True)\n",
    "        return x_splited_train, x_splited_val, y_splited_train, y_splited_val\n",
    "    \n",
    "    def preprocess(self):\n",
    "        train = self.read_csv()\n",
    "        train_x = self.reshape(train)\n",
    "        train_y = self.label_to_vector(train)\n",
    "        if self.resize != None:\n",
    "            train_x = self.resize(train_x)\n",
    "        train_x, val_x, train_y, val_y = self.split(train_x, train_y)\n",
    "        \n",
    "        return train_x, val_x, train_y, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122ae472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T09:53:17.664938Z",
     "start_time": "2021-08-22T09:53:17.653922Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def baseline_model(input_size):\n",
    "        inputs = tf.keras.layers.Input(input_size)\n",
    "\n",
    "        bn = tf.keras.layers.BatchNormalization()(inputs)\n",
    "        conv = tf.keras.layers.Conv2D(128, kernel_size=5, strides=1, padding='same', activation='relu')(bn)\n",
    "        bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "        conv = tf.keras.layers.Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "        pool = tf.keras.layers.MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "        bn = tf.keras.layers.BatchNormalization()(pool)\n",
    "        conv = tf.keras.layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "        bn = tf.keras.layers.BatchNormalization()(conv)\n",
    "        conv = tf.keras.layers.Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "        pool = tf.keras.layers.MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "        flatten = tf.keras.layers.Flatten()(pool)\n",
    "\n",
    "        bn = tf.keras.layers.BatchNormalization()(flatten)\n",
    "        dense = tf.keras.layers.Dense(1000, activation='relu')(bn)\n",
    "\n",
    "        bn = tf.keras.layers.BatchNormalization()(dense)\n",
    "        outputs = tf.keras.layers.Dense(10, activation='softmax')(bn)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def efficientnet_b0(input_size):\n",
    "        effnet = tf.keras.applications.EfficientNetB0(\n",
    "            include_top=True,\n",
    "            weights=None,\n",
    "            input_shape=(input_size, input_size, 3),\n",
    "            classes=10,\n",
    "            classifier_activation=\"softmax\",\n",
    "        )\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(effnet)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def efficientnet_b1(input_size):\n",
    "        effnet = tf.keras.applications.EfficientNetB1(\n",
    "            include_top=True,\n",
    "            weights=None,\n",
    "            input_shape=(input_size, input_size, 3),\n",
    "            classes=10,\n",
    "            classifier_activation=\"softmax\",\n",
    "        )\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(effnet)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def efficientnet_b2(input_size):\n",
    "        effnet = tf.keras.applications.EfficientNetB2(\n",
    "            include_top=True,\n",
    "            weights=None,\n",
    "            input_shape=(input_size, input_size, 3),\n",
    "            classes=10,\n",
    "            classifier_activation=\"softmax\",\n",
    "        )\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(effnet)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc66a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T09:53:17.680920Z",
     "start_time": "2021-08-22T09:53:17.666921Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6daf995",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T09:53:17.695919Z",
     "start_time": "2021-08-22T09:53:17.683920Z"
    }
   },
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self, x_train, y_train, x_val, y_val, model, epoch, batch, loss, optimizer, metrics, save_path):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        self.model = model\n",
    "        self.batch = batch\n",
    "        self.epoch = epoch\n",
    "        self.callbacks = self.callback()\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.metrics = metrics\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def callback(self):\n",
    "        model_save_path = self.save_path + \"ckp-epoch-{epoch:02d}.h5\"\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=model_save_path,\n",
    "            monitor=\"val_accuracy\",\n",
    "            save_best_only=True,\n",
    "            save_freq=5,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor=\"val_loss\", verbose=1, patience=10),\n",
    "\n",
    "        reduce_LR = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=1,\n",
    "                              min_lr=0.00001, verbose=1, mode=\"min\")\n",
    "        \n",
    "        return model_checkpoint_callback, early_stopping, reduce_LR\n",
    "    \n",
    "    def run(self):\n",
    "        model = self.model\n",
    "        model.compile(loss=self.loss, optimizer=self.optimizer, metrics=[self.metrics])\n",
    "        model.summary()\n",
    "        \n",
    "        history = model.fit(self.x_train, self.y_train, batch_size=self.batch, epochs=self.epoch, callbacks=self.callbacks, validation_data=(self.x_valid, self.y_valid))\n",
    "        \n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5c6139b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T09:53:18.078844Z",
     "start_time": "2021-08-22T09:53:17.697921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "path: dataset/train.csv\n",
      "fraction: 0.2\n",
      "resize: None\n",
      "SEED: 3788\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "datast = Dataset(\"dataset/train.csv\", 0.2)\n",
    "train_x, val_x, train_y, val_y = datast.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f79a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
